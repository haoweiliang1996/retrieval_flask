{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256*4\n",
    "folder_name = 'demo//'\n",
    "import mxnet as mx\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_multi_predict(model_name,epoch_num,tt):\n",
    "    print(model_name,epoch_num)\n",
    "    batch_size = 256*4\n",
    "    #sym, arg_params, aux_params = mx.model.load_checkpoint('fine-tuned-firstclass-res18-use-resize', 25)\n",
    "    sym, arg_params, aux_params = mx.model.load_checkpoint(model_name,epoch_num)\n",
    "    mod = mx.mod.Module(symbol=sym, context=mx.gpu(), label_names=None)\n",
    "    longth_ = int(160/8*7)\n",
    "    width_ = int(110/8*7)\n",
    "    mod.bind(for_training=False, data_shapes=[('data', (batch_size,3,longth_,width_))], \n",
    "             label_shapes=mod._label_shapes)\n",
    "    mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "    augs = mx.image.CreateAugmenter(data_shape=(3,longth_, width_),rand_crop=True,rand_resize=False, rand_mirror=True, brightness=0.125, contrast=0.125, rand_gray=0.05,saturation=0.125, pca_noise=0, inter_method=10)\n",
    "    final_res = None\n",
    "    # define a simple data batch\n",
    "    for i in range(tt):\n",
    "        print(i)\n",
    "        val_iter= mx.image.ImageIter(batch_size=batch_size, data_shape=(3, longth_, width_), label_width=1,\n",
    "                                       path_imgidx=folder_name+'cloth_val.idx', path_imgrec=folder_name+'cloth_val.rec', shuffle=False,\n",
    "                                       aug_list=augs)\n",
    "        res = mod.predict(val_iter,always_output_list=True,num_batch=10)\n",
    "        if final_res is None:\n",
    "            final_res = res\n",
    "        else:\n",
    "            final_res += res\n",
    "    del mod\n",
    "    return final_res\n",
    "#res_list.append(do_multi_predict('fine-tuned-firstclass-res50-use-resize-use-lr_sch', 65,20))\n",
    "#res_list.append(do_multi_predict('fine-tuned-firstclass-res18-use-resize', 25,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tuned-firstclass-res152-use-resize-use-lr_sch 30\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "res_list.append(do_multi_predict('fine-tuned-firstclass-res152-use-resize-use-lr_sch', 30,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('model_avage_grab.pickle','wb') as f:\\n    pickle.dump(res_list,f)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('./model_avage_grab.pickle','rb') as f:\n",
    "    res_list = pickle.load(f)\n",
    "print(len(res_list[0]))\n",
    "'''\n",
    "with open('model_avage_grab.pickle','wb') as f:\n",
    "    pickle.dump(res_list,f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256 * 8\n",
    "#sym, arg_params, aux_params = mx.model.load_checkpoint('fine-tuned-firstclass-res18-use-resize', 25)\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('fine-tuned-firstclass-res50-use-resize-use-lr_sch', 65)\n",
    "mod = mx.mod.Module(symbol=sym, context=mx.gpu(), label_names=None)\n",
    "longth_ = int(160/8*7)\n",
    "width_ = int(110/8*7)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (batch_size,3,longth_,width_))], \n",
    "         label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting\n",
    "\n",
    "We first define helper functions for downloading an image and performing the\n",
    "prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_name = 'first_class_data_nopre//'\n",
    "augs = mx.image.CreateAugmenter(data_shape=(3,longth_, width_),rand_crop=True,rand_resize=False, rand_mirror=True, brightness=0.125, contrast=0.125, rand_gray=0.05,saturation=0.125, pca_noise=0, inter_method=10)\n",
    "final_res = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef predict(url):\\n    img = get_image(url, show=True)\\n    # compute the predict probabilities\\n    mod.forward(Batch([mx.nd.array(img)]))\\n    prob = mod.get_outputs()[0].asnumpy()\\n    # print the top-5\\n    prob = np.squeeze(prob)\\n    a = np.argsort(prob)[::-1]\\n    for i in a[0:5]:\\n        print('probability=%f, class=%s' %(prob[i], labels[i]))\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "# define a simple data batch\n",
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "tt = 10\n",
    "for i in range(tt):\n",
    "    val_iter= mx.image.ImageIter(batch_size=batch_size, data_shape=(3, longth_, width_), label_width=1,\n",
    "                                   path_imgidx=folder_name+'cloth_val.idx', path_imgrec=folder_name+'cloth_val.rec', shuffle=False,\n",
    "                                   aug_list=augs)\n",
    "    res = mod.predict(val_iter,always_output_list=True,num_batch=10)\n",
    "    if final_res is None:\n",
    "        final_res = res\n",
    "    else:\n",
    "        final_res += res\n",
    "'''\n",
    "def predict(url):\n",
    "    img = get_image(url, show=True)\n",
    "    # compute the predict probabilities\n",
    "    mod.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = mod.get_outputs()[0].asnumpy()\n",
    "    # print the top-5\n",
    "    prob = np.squeeze(prob)\n",
    "    a = np.argsort(prob)[::-1]\n",
    "    for i in a[0:5]:\n",
    "        print('probability=%f, class=%s' %(prob[i], labels[i]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 7.  1.  0. ...,  4.  4.  1.]\n",
      "<NDArray 7108 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "longth_ = int(160/8*7)\n",
    "width_ = int(110/8*7)\n",
    "augs = mx.image.CreateAugmenter(data_shape=(3,longth_, width_),rand_crop=True,rand_resize=False, rand_mirror=True, brightness=0.125, contrast=0.125, rand_gray=0.05,saturation=0.125, pca_noise=0, inter_method=10)\n",
    "val_iter= mx.image.ImageIter(batch_size=batch_size, data_shape=(3, longth_, width_), label_width=1,\n",
    "                               path_imgidx=folder_name+'cloth_val.idx', path_imgrec=folder_name+'cloth_val.rec', shuffle=False,\n",
    "                               aug_list=augs)\n",
    "val_label = None\n",
    "for batch in val_iter:\n",
    "    l = batch.label[0]\n",
    "    if val_label is None:\n",
    "        val_label = l\n",
    "    else:\n",
    "        val_label = mx.ndarray.concat(val_label,l,dim=0)\n",
    "    #print(mx.ndarray.concat(l,l,dim=1))\n",
    "val_label = val_label[:7108].as_in_context(mx.gpu(0))\n",
    "print(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7108, 8)\n"
     ]
    }
   ],
   "source": [
    "print(res_list[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.63956105796285878)\n",
      "('top_k_accuracy_2', 0.78474957794034894)\n"
     ]
    }
   ],
   "source": [
    "def eval_avage(fea_list):\n",
    "    res_final = mx.nd.zeros(fea_list[0].shape,ctx=mx.gpu())\n",
    "    #res_final = final_res[0]\n",
    "    for i in fea_list:\n",
    "        res_final += i\n",
    "    res_final/= len(fea_list)\n",
    "    acc = mx.metric.Accuracy()\n",
    "    top2 = mx.metric.TopKAccuracy(top_k=2)\n",
    "    acc.update(labels=[val_label],preds=[res_final])\n",
    "    top2.update(labels=[val_label],preds=[res_final])\n",
    "    print(acc.get())\n",
    "    print(top2.get())\n",
    "def eval_avage_thre(fea_list):\n",
    "    res_final = mx.nd.zeros(fea_list[0].shape,ctx=mx.gpu())\n",
    "    #res_final = final_res[0]\n",
    "    for i in fea_list:\n",
    "        res_final += i\n",
    "    res_final/= len(fea_list)\n",
    "    acc = mx.metric.Accuracy()\n",
    "    top2 = mx.metric.TopKAccuracy(top_k=2)\n",
    "    acc.update(labels=[val_label],preds=[res_final])\n",
    "    top2.update(labels=[val_label],preds=[res_final])\n",
    "    print(acc.get())\n",
    "    print(top2.get())\n",
    "eval_avage_thre(  res_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.93415869442881261)\n",
      "('top_k_accuracy_2', 0.9800225098480585)\n",
      "('top_k_accuracy_3', 0.99071468767585824)\n"
     ]
    }
   ],
   "source": [
    "fea_list = res_list[2]\n",
    "res_final = mx.nd.zeros(fea_list[0].shape,ctx=mx.gpu())\n",
    "#res_final = final_res[0]\n",
    "for i in fea_list:\n",
    "    res_final += i\n",
    "res_final/= len(fea_list)\n",
    "dd= res_final[3]\n",
    "acc = mx.metric.Accuracy()\n",
    "top2 = mx.metric.TopKAccuracy(top_k=2)\n",
    "top3 = mx.metric.TopKAccuracy(top_k=3)\n",
    "acc.update(labels=[val_label],preds=[res_final])\n",
    "top2.update(labels=[val_label],preds=[res_final])\n",
    "top3.update(labels=[val_label],preds=[res_final])\n",
    "print(acc.get())\n",
    "print(top2.get())\n",
    "print(top3.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = res_final.asnumpy()\n",
    "l = val_label.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 285 0 34 468\n",
      "0.09622960045019696\n",
      "0.03052898142937535\n"
     ]
    }
   ],
   "source": [
    "ff = []\n",
    "tt = []\n",
    "fff = []\n",
    "ttf = []\n",
    "allf = []\n",
    "for i in range(len(p)):\n",
    "    pp = p[i]\n",
    "    mm = pp.argmax()\n",
    "    second = (pp.argsort()[-3:])\n",
    "    if mm != l[i]:\n",
    "        allf.append(pp[mm])\n",
    "    if mm != l[i] and pp[mm] <0.75:\n",
    "        ff.append(pp[mm])\n",
    "        if l[i] not in second:\n",
    "            fff.append(pp[mm])\n",
    "    else:\n",
    "        if pp[mm] < 0.75:\n",
    "            tt.append(pp[mm])\n",
    "            if l[i] not in second:\n",
    "                ttf.append(pp[mm])\n",
    "print(len(tt),len(ff),len(ttf),len(fff),len(allf))\n",
    "print((len(tt)+len(ff))/7108)\n",
    "#print(tt)\n",
    "print((len(allf)+len(fff)-len(ff))/7108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.88716938660664035)\n",
      "('top_k_accuracy_2', 0.95779403489026449)\n"
     ]
    }
   ],
   "source": [
    "acc = mx.metric.Accuracy()\n",
    "top2 = mx.metric.TopKAccuracy(top_k=2)\n",
    "acc.update(labels=[val_label[:7108]],preds=[res_final])\n",
    "top2.update(labels=[val_label[:7108]],preds=[res_final])\n",
    "print(acc.get())\n",
    "print(top2.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7108, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = res[0] + res[0]\n",
    "zero = np.zeros((7108,8))\n",
    "zero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tuned-firstclass-res152-use-resize-use-lr_sch 30\n",
      "CPU times: user 280 ms, sys: 68 ms, total: 348 ms\n",
      "Wall time: 241 ms\n",
      "1 10 3 4 5 6 7 8\n",
      "\n",
      "[[  8.17690961e-05   4.03449150e-08   4.80921926e-07   9.99914527e-01\n",
      "    2.71953180e-08   1.71702993e-06   1.31430693e-06   5.71130485e-08]]\n",
      "<NDArray 1x8 @cpu(0)> 上装\n"
     ]
    }
   ],
   "source": [
    "def do_multi_predict(model_name,epoch_num,tt):\n",
    "    print(model_name,epoch_num)\n",
    "    batch_size = 1\n",
    "    #sym, arg_params, aux_params = mx.model.load_checkpoint('fine-tuned-firstclass-res18-use-resize', 25)\n",
    "    sym, arg_params, aux_params = mx.model.load_checkpoint(model_name,epoch_num)\n",
    "    mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
    "    longth_ = int(160/8*7)\n",
    "    width_ = int(110/8*7)\n",
    "    mod.bind(for_training=False, data_shapes=[('data', (batch_size,3,longth_,width_))], \n",
    "             label_shapes=mod._label_shapes)\n",
    "    mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "    augs = mx.image.CreateAugmenter(data_shape=(3,longth_, width_),rand_crop=True,rand_resize=False, rand_mirror=True, brightness=0.125, contrast=0.125, rand_gray=0.05,saturation=0.125, pca_noise=0, inter_method=10)\n",
    "    final_res = None\n",
    "    # define a simple data batch\n",
    "    for i in range(tt):\n",
    "        val_iter= mx.image.ImageIter(batch_size=batch_size, data_shape=(3, longth_, width_), label_width=1,\n",
    "                                       path_imgidx=folder_name+'cloth_val.idx', path_imgrec=folder_name+'cloth_val.rec', shuffle=False,\n",
    "                                       aug_list=augs)\n",
    "        res = mod.predict(val_iter,always_output_list=True)\n",
    "        if final_res is None:\n",
    "            final_res = res\n",
    "        else:\n",
    "            final_res += res\n",
    "    del mod\n",
    "    return final_res\n",
    "%time fea_list = (do_multi_predict('fine-tuned-firstclass-res152-use-resize-use-lr_sch', 30,20))\n",
    "\n",
    "res_final = mx.nd.zeros(fea_list[0].shape,ctx=mx.cpu())\n",
    "#res_final = final_res[0]\n",
    "for i in fea_list:\n",
    "    res_final += i\n",
    "res_final/= len(fea_list)\n",
    "print(1,10,3,4,5,6,7,8)\n",
    "rrrr =  ['帽子','鞋子','披带类','上装','裤子','裙子','连体装','包包']\n",
    "print(res_final,rrrr[res_final[0].asnumpy().argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- INSERT SOURCE DOWNLOAD BUTTONS -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
